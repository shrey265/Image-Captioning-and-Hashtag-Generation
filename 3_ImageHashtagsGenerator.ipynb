{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The dataset zip file path present in google drive in zip_file_path variable. Output directory path in output_directory variable."
      ],
      "metadata": {
        "id": "SzKavkpyaEgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = \"/content/drive/MyDrive/GenAI/harrison.zip\"\n",
        "output_directory = \"/content/dataset\""
      ],
      "metadata": {
        "id": "tfa_TkExaKKD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c84aed4"
      },
      "source": [
        "### 1. Mount Google Drive\n",
        "\n",
        "First, you need to mount your Google Drive to make its contents accessible in Colab. This will prompt you to authorize Colab to access your Google Drive files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82260eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cba1c08-0749-4e51-c19d-2fb4c7e508da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "jfJmlDUGhK6r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the dataset"
      ],
      "metadata": {
        "id": "d61HuEpma9Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "# Unzip the file using the shell command\n",
        "# You can also use Python's 'zipfile' module if preferred, as shown in previous examples.\n",
        "!unzip -o {zip_file_path} -d {output_directory}\n",
        "\n",
        "print(f\"Attempted to unzip '{zip_file_path}' to '{output_directory}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js49u7tkl0-t",
        "outputId": "74862499-baba-4a0f-bc05-8ca63677b25a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/GenAI/harrison.zip\n",
            "  inflating: /content/dataset/harrison_features.npz  \n",
            "  inflating: /content/dataset/tag_list.txt  \n",
            "Attempted to unzip '/content/drive/MyDrive/GenAI/harrison.zip' to '/content/dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset in a dataframe"
      ],
      "metadata": {
        "id": "H3HgKny0cA6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "npz_file_path = output_directory + '/harrison_features.npz'\n",
        "# Load the .npz file\n",
        "with np.load(npz_file_path) as data:\n",
        "    # Use 'imagenet_fc_layers' as the image features based on inspection of available keys\n",
        "    if 'imagenet_fc_layers' in data.files:\n",
        "        image_features = data['imagenet_fc_layers']\n",
        "        print(f\"Successfully loaded image features with shape: {image_features.shape}\")\n",
        "    else:\n",
        "        print(f\"Error: 'imagenet_fc_layers' not found in {npz_file_path}. Available keys: {data.files}\")\n",
        "        image_features = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ0WOnmkbaOd",
        "outputId": "72a52c3e-316e-4ddb-f141-1e0ccb934ade"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded image features with shape: (57383, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_list_file_path = output_directory + '/tag_list.txt'\n",
        "\n",
        "# Load hashtags from the text file\n",
        "with open(tag_list_file_path, 'r') as f:\n",
        "    hashtags_list = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "print(f\"Successfully loaded {len(hashtags_list)} hashtags.\")\n",
        "# Display the first 5 hashtags to verify\n",
        "print(\"First 5 hashtags:\", hashtags_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOY89OhabeZY",
        "outputId": "a05f084d-0d30-4eda-995e-fc797a56158e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded 57383 hashtags.\n",
            "First 5 hashtags: ['sea instapic instagram trip travel', 'sea', 'sea love', 'beach sea trip island japan', 'sun sand sea sky friend beach thailand trip adventure']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the loaded features and hashtags\n",
        "df_combined = pd.DataFrame({\n",
        "    'features': list(image_features),\n",
        "    'hashtags': hashtags_list\n",
        "})\n",
        "\n",
        "# Limit the DataFrame to the first 10000 samples to save training time\n",
        "df = df_combined.head(10000)\n",
        "\n",
        "print(f\"Combined DataFrame created with shape: {df_combined.shape}\")\n",
        "print(f\"Limited DataFrame created with shape: {df.shape}\")\n",
        "print(\"Limited DataFrame Head:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "084V2fr9bmhR",
        "outputId": "e964b4ce-10e6-4081-d6f8-91544033d3a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame created with shape: (57383, 2)\n",
            "Limited DataFrame created with shape: (10000, 2)\n",
            "Limited DataFrame Head:\n",
            "                                            features  \\\n",
            "0  [0.8123088, 1.5523993, 0.0, 2.5534768, 1.76293...   \n",
            "1  [0.12911989, 0.0, 0.16080879, 0.18392688, 0.09...   \n",
            "2  [0.42463303, 0.15550624, 0.014838985, 0.086087...   \n",
            "3  [0.05410369, 0.32260185, 0.16083369, 0.3008105...   \n",
            "4  [0.027175432, 1.572316, 0.23366477, 1.017643, ...   \n",
            "\n",
            "                                            hashtags  \n",
            "0                 sea instapic instagram trip travel  \n",
            "1                                                sea  \n",
            "2                                           sea love  \n",
            "3                        beach sea trip island japan  \n",
            "4  sun sand sea sky friend beach thailand trip ad...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean hashtags\n",
        "def clean_hashtags(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'#', '', text)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "df['hashtags'] = df['hashtags'].apply(clean_hashtags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaMG3SvpkSW4",
        "outputId": "5f530901-0c04-46e2-98e5-5c149b3db163"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-223168973.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hashtags'] = df['hashtags'].apply(clean_hashtags)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string features to numpy arrays if stored as text\n",
        "if isinstance(df.iloc[0]['features'], str):\n",
        "    df['features'] = df['features'].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=','))"
      ],
      "metadata": {
        "id": "OzdoEfokkWcB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 2️⃣ Preprocess Text and Build Vocabulary\n",
        "# ===============================================================\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "hashtags_list = [h.split() for h in df['hashtags']]\n",
        "all_tags = [t for tags in hashtags_list for t in tags]\n",
        "counter = Counter(all_tags)\n",
        "\n",
        "# Keep top-K hashtags (reduce vocab size)\n",
        "TOP_K = 5000\n",
        "most_common = counter.most_common(TOP_K)\n",
        "vocab = ['<pad>', '<start>', '<end>', '<unk>'] + [w for w, _ in most_common]\n",
        "word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "idx2word = {i:w for w,i in word2idx.items()}"
      ],
      "metadata": {
        "id": "tr4X0Kfyka7f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_tags(tags):\n",
        "    ids = [word2idx.get(w, word2idx['<unk>']) for w in tags]\n",
        "    return [word2idx['<start>']] + ids + [word2idx['<end>']]\n",
        "\n",
        "def pad_sequence(seq, max_len=10):\n",
        "    seq = seq[:max_len]\n",
        "    seq += [word2idx['<pad>']] * (max_len - len(seq))\n",
        "    return seq\n",
        "\n",
        "# Prepare sequences\n",
        "# First, split the strings in 'hashtags' column into lists of tags\n",
        "df['hashtags_split'] = df['hashtags'].apply(lambda x: x.split())\n",
        "\n",
        "# Now apply encode_tags to the newly created 'hashtags_split' column\n",
        "df['encoded'] = df['hashtags_split'].apply(encode_tags)\n",
        "\n",
        "MAX_LEN = 10\n",
        "df['padded'] = df['encoded'].apply(lambda x: pad_sequence(x, MAX_LEN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAhMPJcckeQf",
        "outputId": "f6b7e867-c946-4a6f-bb12-5717496866e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-444556984.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['hashtags_split'] = df['hashtags'].apply(lambda x: x.split())\n",
            "/tmp/ipython-input-444556984.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['encoded'] = df['hashtags_split'].apply(encode_tags)\n",
            "/tmp/ipython-input-444556984.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['padded'] = df['encoded'].apply(lambda x: pad_sequence(x, MAX_LEN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 3️⃣ Create Dataset Class\n",
        "# ===============================================================\n",
        "\n",
        "class HashtagDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.X = np.stack(df['features'].to_numpy())\n",
        "        self.y = np.stack(df['padded'].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feat = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        seq = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "        return feat, seq\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "train_data = HashtagDataset(train_df)\n",
        "val_data = HashtagDataset(val_df)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "mOqYkztEkhP5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "m7OBE7y8oWCM",
        "outputId": "63578eba-052d-4f83-91a0-2fa776535419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               features  \\\n",
              "0     [0.8123088, 1.5523993, 0.0, 2.5534768, 1.76293...   \n",
              "1     [0.12911989, 0.0, 0.16080879, 0.18392688, 0.09...   \n",
              "2     [0.42463303, 0.15550624, 0.014838985, 0.086087...   \n",
              "3     [0.05410369, 0.32260185, 0.16083369, 0.3008105...   \n",
              "4     [0.027175432, 1.572316, 0.23366477, 1.017643, ...   \n",
              "...                                                 ...   \n",
              "9995  [1.2312934, 0.01216483, 0.15034737, 0.06016748...   \n",
              "9996  [0.97869843, 0.36804786, 0.1355541, 0.5787414,...   \n",
              "9997  [0.05007997, 0.010740085, 1.0760548, 0.377246,...   \n",
              "9998  [0.4592604, 0.0, 0.0, 0.0, 0.024754986, 0.2424...   \n",
              "9999  [0.3650061, 0.19146256, 0.006673652, 0.2230274...   \n",
              "\n",
              "                                               hashtags  \\\n",
              "0                    sea instapic instagram trip travel   \n",
              "1                                                   sea   \n",
              "2                                              sea love   \n",
              "3                           beach sea trip island japan   \n",
              "4     sun sand sea sky friend beach thailand trip ad...   \n",
              "...                                                 ...   \n",
              "9995                                      yellow flower   \n",
              "9996  yellow green beautiful tagsta fashiondiaries f...   \n",
              "9997                                summer happy yellow   \n",
              "9998                                photo nature yellow   \n",
              "9999  cat flower yellow catsofinstagram cute bluesky...   \n",
              "\n",
              "                                         hashtags_split  \\\n",
              "0              [sea, instapic, instagram, trip, travel]   \n",
              "1                                                 [sea]   \n",
              "2                                           [sea, love]   \n",
              "3                     [beach, sea, trip, island, japan]   \n",
              "4     [sun, sand, sea, sky, friend, beach, thailand,...   \n",
              "...                                                 ...   \n",
              "9995                                   [yellow, flower]   \n",
              "9996  [yellow, green, beautiful, tagsta, fashiondiar...   \n",
              "9997                            [summer, happy, yellow]   \n",
              "9998                            [photo, nature, yellow]   \n",
              "9999  [cat, flower, yellow, catsofinstagram, cute, b...   \n",
              "\n",
              "                                            encoded  \\\n",
              "0                       [1, 10, 73, 37, 101, 43, 2]   \n",
              "1                                        [1, 10, 2]   \n",
              "2                                     [1, 10, 5, 2]   \n",
              "3                     [1, 20, 10, 101, 245, 168, 2]   \n",
              "4     [1, 24, 116, 10, 46, 4, 20, 260, 101, 195, 2]   \n",
              "...                                             ...   \n",
              "9995                                  [1, 8, 17, 2]   \n",
              "9996     [1, 8, 40, 18, 884, 840, 877, 624, 898, 2]   \n",
              "9997                              [1, 52, 14, 8, 2]   \n",
              "9998                              [1, 62, 21, 8, 2]   \n",
              "9999     [1, 87, 17, 8, 349, 15, 209, 21, 7, 47, 2]   \n",
              "\n",
              "                                          padded  \n",
              "0           [1, 10, 73, 37, 101, 43, 2, 0, 0, 0]  \n",
              "1                [1, 10, 2, 0, 0, 0, 0, 0, 0, 0]  \n",
              "2                [1, 10, 5, 2, 0, 0, 0, 0, 0, 0]  \n",
              "3         [1, 20, 10, 101, 245, 168, 2, 0, 0, 0]  \n",
              "4     [1, 24, 116, 10, 46, 4, 20, 260, 101, 195]  \n",
              "...                                          ...  \n",
              "9995             [1, 8, 17, 2, 0, 0, 0, 0, 0, 0]  \n",
              "9996  [1, 8, 40, 18, 884, 840, 877, 624, 898, 2]  \n",
              "9997            [1, 52, 14, 8, 2, 0, 0, 0, 0, 0]  \n",
              "9998            [1, 62, 21, 8, 2, 0, 0, 0, 0, 0]  \n",
              "9999     [1, 87, 17, 8, 349, 15, 209, 21, 7, 47]  \n",
              "\n",
              "[10000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70b2eb9d-b9f1-4103-a617-23bf985b2076\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>features</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>hashtags_split</th>\n",
              "      <th>encoded</th>\n",
              "      <th>padded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.8123088, 1.5523993, 0.0, 2.5534768, 1.76293...</td>\n",
              "      <td>sea instapic instagram trip travel</td>\n",
              "      <td>[sea, instapic, instagram, trip, travel]</td>\n",
              "      <td>[1, 10, 73, 37, 101, 43, 2]</td>\n",
              "      <td>[1, 10, 73, 37, 101, 43, 2, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.12911989, 0.0, 0.16080879, 0.18392688, 0.09...</td>\n",
              "      <td>sea</td>\n",
              "      <td>[sea]</td>\n",
              "      <td>[1, 10, 2]</td>\n",
              "      <td>[1, 10, 2, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.42463303, 0.15550624, 0.014838985, 0.086087...</td>\n",
              "      <td>sea love</td>\n",
              "      <td>[sea, love]</td>\n",
              "      <td>[1, 10, 5, 2]</td>\n",
              "      <td>[1, 10, 5, 2, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.05410369, 0.32260185, 0.16083369, 0.3008105...</td>\n",
              "      <td>beach sea trip island japan</td>\n",
              "      <td>[beach, sea, trip, island, japan]</td>\n",
              "      <td>[1, 20, 10, 101, 245, 168, 2]</td>\n",
              "      <td>[1, 20, 10, 101, 245, 168, 2, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.027175432, 1.572316, 0.23366477, 1.017643, ...</td>\n",
              "      <td>sun sand sea sky friend beach thailand trip ad...</td>\n",
              "      <td>[sun, sand, sea, sky, friend, beach, thailand,...</td>\n",
              "      <td>[1, 24, 116, 10, 46, 4, 20, 260, 101, 195, 2]</td>\n",
              "      <td>[1, 24, 116, 10, 46, 4, 20, 260, 101, 195]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>[1.2312934, 0.01216483, 0.15034737, 0.06016748...</td>\n",
              "      <td>yellow flower</td>\n",
              "      <td>[yellow, flower]</td>\n",
              "      <td>[1, 8, 17, 2]</td>\n",
              "      <td>[1, 8, 17, 2, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>[0.97869843, 0.36804786, 0.1355541, 0.5787414,...</td>\n",
              "      <td>yellow green beautiful tagsta fashiondiaries f...</td>\n",
              "      <td>[yellow, green, beautiful, tagsta, fashiondiar...</td>\n",
              "      <td>[1, 8, 40, 18, 884, 840, 877, 624, 898, 2]</td>\n",
              "      <td>[1, 8, 40, 18, 884, 840, 877, 624, 898, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>[0.05007997, 0.010740085, 1.0760548, 0.377246,...</td>\n",
              "      <td>summer happy yellow</td>\n",
              "      <td>[summer, happy, yellow]</td>\n",
              "      <td>[1, 52, 14, 8, 2]</td>\n",
              "      <td>[1, 52, 14, 8, 2, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>[0.4592604, 0.0, 0.0, 0.0, 0.024754986, 0.2424...</td>\n",
              "      <td>photo nature yellow</td>\n",
              "      <td>[photo, nature, yellow]</td>\n",
              "      <td>[1, 62, 21, 8, 2]</td>\n",
              "      <td>[1, 62, 21, 8, 2, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>[0.3650061, 0.19146256, 0.006673652, 0.2230274...</td>\n",
              "      <td>cat flower yellow catsofinstagram cute bluesky...</td>\n",
              "      <td>[cat, flower, yellow, catsofinstagram, cute, b...</td>\n",
              "      <td>[1, 87, 17, 8, 349, 15, 209, 21, 7, 47, 2]</td>\n",
              "      <td>[1, 87, 17, 8, 349, 15, 209, 21, 7, 47]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70b2eb9d-b9f1-4103-a617-23bf985b2076')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70b2eb9d-b9f1-4103-a617-23bf985b2076 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70b2eb9d-b9f1-4103-a617-23bf985b2076');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-479eca5f-780f-4cda-9df2-3d40525f8185\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-479eca5f-780f-4cda-9df2-3d40525f8185')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-479eca5f-780f-4cda-9df2-3d40525f8185 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f0fd21f1-08cd-4722-b59e-bdb70939d6d0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f0fd21f1-08cd-4722-b59e-bdb70939d6d0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hashtags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8028,\n        \"samples\": [\n          \"the day house working friday tired blonde\",\n          \"friend friday love girl boy party drink weekend\",\n          \"selfie boyfriend lovehim\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hashtags_split\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"padded\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 4️⃣ Define Generative Model\n",
        "# ===============================================================\n",
        "\n",
        "class TinyHashtagGenerator(nn.Module):\n",
        "    def __init__(self, feature_dim, vocab_size, embed_dim=128, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.feature_proj = nn.Linear(feature_dim, embed_dim)\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        # project features and treat them as first token\n",
        "        img_embed = self.feature_proj(features).unsqueeze(1)\n",
        "        cap_embed = self.embed(captions[:, :-1])\n",
        "        inputs = torch.cat([img_embed, cap_embed], dim=1)\n",
        "        output, _ = self.gru(inputs)\n",
        "        logits = self.fc(output)\n",
        "        return logits\n",
        "\n",
        "# Get feature dimension automatically\n",
        "feature_dim = len(df.iloc[0]['features'])\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TinyHashtagGenerator(feature_dim, vocab_size).to(device)"
      ],
      "metadata": {
        "id": "I-5hWj1WkhzI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "_mTV7tAqcQAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 5️⃣ Training Setup\n",
        "# ===============================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2idx['<pad>'])\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "EPOCHS = 30"
      ],
      "metadata": {
        "id": "m7F4OqZCklzp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 6️⃣ Train the Model\n",
        "# ===============================================================\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for feats, seqs in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "        feats, seqs = feats.to(device), seqs.to(device)\n",
        "        logits = model(feats, seqs)\n",
        "        loss = criterion(logits.reshape(-1, vocab_size), seqs.reshape(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1} Train Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaQnY--1koTg",
        "outputId": "036858a3-4e2f-45a1-cc5c-64c36c39daff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 141/141 [00:05<00:00, 25.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 0.9378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 141/141 [00:05<00:00, 25.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Train Loss: 0.8907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 141/141 [00:06<00:00, 21.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Train Loss: 0.8634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 141/141 [00:05<00:00, 26.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Train Loss: 0.8354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 141/141 [00:06<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Train Loss: 0.8220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 141/141 [00:05<00:00, 26.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Train Loss: 0.8201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 141/141 [00:05<00:00, 23.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Train Loss: 0.8221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 141/141 [00:06<00:00, 23.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Train Loss: 0.7995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 141/141 [00:05<00:00, 26.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Train Loss: 0.7667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 141/141 [00:06<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Train Loss: 0.7431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 141/141 [00:05<00:00, 26.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Train Loss: 0.7336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 141/141 [00:06<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Train Loss: 0.7458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 141/141 [00:05<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Train Loss: 0.7144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 141/141 [00:05<00:00, 25.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Train Loss: 0.6880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 141/141 [00:06<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Train Loss: 0.6819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 141/141 [00:05<00:00, 26.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Train Loss: 0.7154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 141/141 [00:06<00:00, 20.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Train Loss: 0.6741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 141/141 [00:05<00:00, 25.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Train Loss: 0.6643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 141/141 [00:06<00:00, 21.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Train Loss: 0.6597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 141/141 [00:06<00:00, 23.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Train Loss: 0.6583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 141/141 [00:05<00:00, 25.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Train Loss: 0.6280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 141/141 [00:06<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Train Loss: 0.6376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 141/141 [00:05<00:00, 26.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Train Loss: 0.6011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 141/141 [00:06<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 Train Loss: 0.5707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 141/141 [00:05<00:00, 26.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 Train Loss: 0.5475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 141/141 [00:05<00:00, 23.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 Train Loss: 0.5344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 141/141 [00:06<00:00, 23.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 Train Loss: 0.5400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 141/141 [00:05<00:00, 26.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 Train Loss: 0.5671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 141/141 [00:06<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 Train Loss: 0.5814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 141/141 [00:05<00:00, 26.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 Train Loss: 0.5573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model weights\n",
        "torch.save(model.state_dict(), \"tiny_hashtag_generator.pth\")\n",
        "print(\"✅ Model weights saved as 'tiny_hashtag_generator.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2qj9WfKIL83",
        "outputId": "0d837e26-1961-490a-f5f9-cbe723c5b39b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model weights saved as 'tiny_hashtag_generator.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# ===============================================================\n",
        "# 7️⃣ Hashtag Generation Function\n",
        "# ===============================================================\n",
        "\n",
        "def generate_hashtags(model, feature, max_len=5, temperature=1.0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        feature_tensor = torch.tensor(feature, dtype=torch.float32).unsqueeze(0).to(device) # Shape (1, feature_dim)\n",
        "\n",
        "        # Project the image features once, and ensure it's (1, 1, embed_dim) for concatenation\n",
        "        initial_img_embed_for_cat = model.feature_proj(feature_tensor).unsqueeze(1) # Shape (1, 1, embed_dim)\n",
        "\n",
        "        # Start generating with the <start> token\n",
        "        current_generated_tokens = torch.tensor([[word2idx['<start>']]], dtype=torch.long).to(device) # Shape (1, 1)\n",
        "        hidden = None # Initial hidden state for GRU\n",
        "        tags = []\n",
        "\n",
        "        for i in range(max_len):\n",
        "            # Get the embedding for the last generated token\n",
        "            # This will be <start> in the first iteration\n",
        "            current_token_embed = model.embed(current_generated_tokens[:, -1]).unsqueeze(1) # Shape (1, 1, embed_dim)\n",
        "\n",
        "            if i == 0: # First step of generation\n",
        "                # The GRU input for the first step is image context followed by <start> token embedding\n",
        "                # This mirrors the `torch.cat([img_embed, cap_embed], dim=1)` from `forward`\n",
        "                gru_input_sequence = torch.cat([initial_img_embed_for_cat, current_token_embed], dim=1) # Shape (1, 2, embed_dim)\n",
        "            else: # Subsequent steps\n",
        "                # For autoregressive generation after the first step, feed only the current token embedding\n",
        "                # and rely on the hidden state.\n",
        "                gru_input_sequence = current_token_embed # Shape (1, 1, embed_dim)\n",
        "\n",
        "            # Pass through GRU. The hidden state will be updated and passed to the next iteration.\n",
        "            output, hidden = model.gru(gru_input_sequence, hidden) # output shape (1, seq_len_of_gru_input, hidden_dim)\n",
        "\n",
        "            # Get logits from the output corresponding to the *last* token fed to GRU in this step\n",
        "            logits = model.fc(output[:, -1, :]) / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            next_token_idx = torch.multinomial(probs, 1).item()\n",
        "\n",
        "            if idx2word[next_token_idx] == '<end>':\n",
        "                break\n",
        "\n",
        "            tags.append(idx2word[next_token_idx])\n",
        "            # Append the newly generated token to `current_generated_tokens` for the next iteration\n",
        "            current_generated_tokens = torch.cat([current_generated_tokens, torch.tensor([[next_token_idx]]).to(device)], dim=1)\n",
        "\n",
        "        return ['#' + t for t in tags]"
      ],
      "metadata": {
        "id": "SIOsAI_-krkI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# 8️⃣ Test on a Random Sample\n",
        "# ===============================================================\n",
        "\n",
        "sample_feat = df.iloc[0]['features']\n",
        "predicted_tags = generate_hashtags(model, sample_feat)\n",
        "print(\"Generated Hashtags:\", predicted_tags)\n",
        "print(\"Original Hashtags:\", df.iloc[0]['hashtags'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcmmzp5Oku6x",
        "outputId": "9036bad6-8707-446e-ab5f-213553917c1b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Hashtags: ['#relax', '#friend', '#colour', '#instasize']\n",
            "Original Hashtags: sea instapic instagram trip travel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6158b748"
      },
      "source": [
        "### Test on Multiple Samples\n",
        "\n",
        "This code block will iterate through a few samples from the `df` DataFrame, generate hashtags for each, and print both the original and generated tags for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab1ba92d",
        "outputId": "a7748b28-451d-4a0c-8bc2-f4433b24f270"
      },
      "source": [
        "# Test on a few more samples\n",
        "# You can adjust the range (e.g., from 1 to 6 for 5 samples) to test more or fewer entries\n",
        "for i in range(10200, 10205): # Testing 5 samples (index 1001 through 1005)\n",
        "    sample_feat = df_combined.iloc[i]['features']\n",
        "    predicted_tags = generate_hashtags(model, sample_feat)\n",
        "    print(f\"\\n--- Sample {i+1} ---\")\n",
        "    print(\"Generated Hashtags:\", predicted_tags)\n",
        "    print(\"Original Hashtags:\", df_combined.iloc[i]['hashtags'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 10201 ---\n",
            "Generated Hashtags: ['#blossom', '#pink', '#yellow']\n",
            "Original Hashtags: flower nature instanature instapic natural picoftheday spring yellow trip travel\n",
            "\n",
            "--- Sample 10202 ---\n",
            "Generated Hashtags: ['#family', '#familytime', '#cool']\n",
            "Original Hashtags: yellow followme smile likeforlike\n",
            "\n",
            "--- Sample 10203 ---\n",
            "Generated Hashtags: ['#yellow']\n",
            "Original Hashtags: nikon yellow\n",
            "\n",
            "--- Sample 10204 ---\n",
            "Generated Hashtags: ['#flower', '#yellow', '#mood', '#morning', '#saturday']\n",
            "Original Hashtags: spring flower nature naturelovers yellow\n",
            "\n",
            "--- Sample 10205 ---\n",
            "Generated Hashtags: ['#nyc', '#music', '#handsome', '#boyfriend']\n",
            "Original Hashtags: black white blue yellow fun\n"
          ]
        }
      ]
    }
  ]
}